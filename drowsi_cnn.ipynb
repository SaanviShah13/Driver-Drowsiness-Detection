{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c08df27-55e3-46f1-b6ac-9f3e20580a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.utils.data import random_split, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30080ad8-0ea0-4a31-b8ab-0c476cc8c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir0='PATH OF THE DATASET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b69ac4-718d-48dd-a5b4-231679ec5c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[]\n",
    "paths=[]\n",
    "for dirname, _, filenames in os.walk(dir0):\n",
    "    for filename in filenames:\n",
    "        if not filename.endswith('.txt'):\n",
    "            classes+=[dirname.split('/')[-1]]\n",
    "            paths+=[(os.path.join(dirname, filename))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5defe82d-c811-43fa-afb7-2f0db2c6e8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=list(range(len(classes)))\n",
    "class_names=sorted(set(classes))\n",
    "print(class_names)\n",
    "normal_mapping=dict(zip(class_names,N)) \n",
    "reverse_mapping=dict(zip(N,class_names))       \n",
    "\n",
    "data=pd.DataFrame(columns=['path','class','label'])\n",
    "data['path']=paths\n",
    "data['class']=classes\n",
    "data['label']=data['class'].map(normal_mapping)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d51055e-4315-4d16-ba02-ab463909422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.RandomRotation(10),      # rotate +/- 10 degrees\n",
    "        transforms.RandomHorizontalFlip(),  # reverse 50% of images\n",
    "        transforms.Resize(224),             # resize shortest side to 224 pixels\n",
    "        transforms.CenterCrop(224),         # crop longest side to 224 pixels at center\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a5776-76bd-4996-ba94-dd89e6a2d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path_label_list(df):\n",
    "    path_label_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        path = row['path']\n",
    "        label = row['label']\n",
    "        path_label_list.append((path, label))\n",
    "    return path_label_list\n",
    "\n",
    "path_label = create_path_label_list(data)\n",
    "path_label = random.sample(path_label,len(path_label))\n",
    "print(len(path_label))\n",
    "print(path_label[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c54d04-9ec8-4fcc-ad29-0942c2a1d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_label, transform=None):\n",
    "        self.path_label = path_label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.path_label[idx]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a334ea8-739b-4c3c-b0d3-9215db234b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(pl.LightningDataModule):\n",
    "    def __init__(self, path_label, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.path_label = path_label\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(224),             # resize shortest side to 224 pixels\n",
    "            transforms.CenterCrop(224),         # crop longest side to 224 pixels at center            \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        dataset = CustomDataset(self.path_label, self.transform)\n",
    "        dataset_size = len(dataset)\n",
    "        train_size = int(0.8 * dataset_size) \n",
    "        val_size = dataset_size - train_size\n",
    "        print(train_size,val_size)\n",
    "\n",
    "        self.train_dataset = torch.utils.data.Subset(dataset, range(train_size))\n",
    "        self.val_dataset = torch.utils.data.Subset(dataset, range(train_size, dataset_size))\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train_dataset is not None:\n",
    "            return len(self.train_dataset)\n",
    "        elif self.val_dataset is not None:\n",
    "            return len(self.val_dataset)\n",
    "        else:\n",
    "            return 0        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train_dataset is not None:\n",
    "            return self.train_dataset[index]\n",
    "        elif self.test_dataset is not None:\n",
    "            return self.test_dataset[index]\n",
    "        else:\n",
    "            raise IndexError(\"Index out of range. The dataset is empty.\")\n",
    "\n",
    "    def train_dataset(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataset(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba17db3-eee9-4aa6-b10f-1618481304e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, transform=transform, batch_size=16):\n",
    "        super().__init__()\n",
    "        self.root_dir = dir0\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        data_set = datasets.ImageFolder(root=self.root_dir, transform=self.transform)\n",
    "        \n",
    "        n_data = len(dataset)\n",
    "        n_train = int(0.8 * n_data)\n",
    "        n_val = n_data - n_train\n",
    "        train_dataset, val_dataset =  random_split(dataset, [n_train, n_val])\n",
    "\n",
    "        self.train_dataset = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        self.val_dataset = DataLoader(val_dataset, batch_size=self.batch_size)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.train_dataset\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_dataset\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3512e1-3a8b-4a6c-b0f5-fcdd8ae52af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1 = nn.Linear(16 * 54 * 54, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 20)\n",
    "        self.fc4 = nn.Linear(20, len(class_names))\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 16 * 54 * 54)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = F.relu(self.fc3(X))\n",
    "        X = self.fc4(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        X, y = train_batch\n",
    "        y_hat = self(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        X, y = val_batch\n",
    "        y_hat = self(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        X, y = test_batch\n",
    "        y_hat = self(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b451484-1a1a-474a-be46-f955bc4db770",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(path_label)\n",
    "dataset.setup() \n",
    "train_dataloader = dataset.train_dataloader\n",
    "val_dataloader = dataset.val_dataloader\n",
    "#test_dataloader = dataset.test_dataloader\n",
    "datamodule = DataModule()\n",
    "model = ConvolutionalNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590151de-63a0-4058-9cb5-2e50d1414a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=2)\n",
    "trainer.fit(model, datamodule)\n",
    "val_loader = datamodule.val_dataloader()\n",
    "trainer.test(dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37334d45-d66b-4c73-b6e4-2d14842fc78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in datamodule.val_dataloader():\n",
    "    break\n",
    "im=make_grid(images,nrow=8)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(np.transpose(im.numpy(),(1,2,0)))\n",
    "\n",
    "inv_normalize=transforms.Normalize(mean=[-0.485/0.229,-0.456/0.224,-0.406/0.225],\n",
    "                                   std=[1/0.229,1/0.224,1/0.225])\n",
    "im=inv_normalize(im)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(np.transpose(im.numpy(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c170880e-f270-4619-b5ee-1d16ba63932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")   #\"cuda:0\"\n",
    "\n",
    "model.eval()\n",
    "y_true=[]\n",
    "y_pred=[]\n",
    "with torch.no_grad():\n",
    "    for test_data in datamodule.val_dataloader():\n",
    "        test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "        pred = model(test_images).argmax(dim=1)\n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())\n",
    "\n",
    "print(classification_report(y_true,y_pred,target_names=class_names,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55085f3b-fd46-4a92-9b8f-4baad7a590fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b36e98-fff0-4121-bdc6-9bfac0dc6d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
